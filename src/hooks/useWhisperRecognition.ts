import { useState, useEffect, useRef, useCallback } from 'react';
import { AudioRecorder, transcribeAudio } from '../lib/whisper';

export type RecognitionState = 'idle' | 'starting' | 'listening' | 'processing' | 'stopping';

export interface UseWhisperRecognitionOptions {
  intervalMs?: number; // éŸ³å£°ã‚’é€ä¿¡ã™ã‚‹é–“éš”ï¼ˆãƒŸãƒªç§’ï¼‰
  silenceThreshold?: number; // ç„¡éŸ³ã¨åˆ¤å®šã™ã‚‹é–¾å€¤ï¼ˆ0-1ï¼‰
  whisperPrompt?: string; // Whisper APIã«æ¸¡ã™ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆï¼ˆå›ºæœ‰åè©ã®ãƒ’ãƒ³ãƒˆï¼‰
}

// Whisperã®å¹»è¦šï¼ˆhallucinationï¼‰ã¨ã—ã¦ã‚ˆãå‡ºã‚‹ãƒ•ãƒ¬ãƒ¼ã‚º
// å®Œå…¨ä¸€è‡´ã§ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã™ã‚‹ãƒ•ãƒ¬ãƒ¼ã‚º
const HALLUCINATION_EXACT = [
  'ã”è¦–è´ã‚ã‚ŠãŒã¨ã†ã”ã–ã„ã¾ã—ãŸ',
  'ã”è¦–è´ã‚ã‚ŠãŒã¨ã†ã”ã–ã„ã¾ã™',
  'ã”è¦§ã„ãŸã ãã‚ã‚ŠãŒã¨ã†ã”ã–ã„ã¾ã—ãŸ',
  'ã”è¦§ã„ãŸã ãã‚ã‚ŠãŒã¨ã†ã”ã–ã„ã¾ã™',
  'æœ¬æ—¥ã¯ã”è¦§ã„ãŸã ãã‚ã‚ŠãŒã¨ã†ã”ã–ã„ã¾ã™',
  'æœ¬æ—¥ã¯ã”è¦§ã„ãŸã ãã‚ã‚ŠãŒã¨ã†ã”ã–ã„ã¾ã—ãŸ',
  'ã‚ã‚ŠãŒã¨ã†ã”ã–ã„ã¾ã—ãŸ',
  'ã‚ã‚ŠãŒã¨ã†ã”ã–ã„ã¾ã™',
  'ãŠç–²ã‚Œæ§˜ã§ã—ãŸ',
  'ã‚ˆã„ä¸€æ—¥ã‚’',
  'è‰¯ã„ä¸€æ—¥ã‚’',
  'ãŠã‚„ã™ã¿ãªã•ã„',
  'ã•ã‚ˆã†ãªã‚‰',
  'ã¾ãŸã­',
  'ãƒã‚¤ãƒã‚¤',
  'çµ‚ã‚ã‚Š',
  'ãŠã—ã¾ã„',
  'Thank you for watching',
  'Thanks for watching',
  'Subscribe',
  'Like and subscribe',
  'MochiMochi',
  'Amara.org',
  'www.',
  'http',
  '.com',
  '.jp',
  '...',
  'ã€‚ã€‚ã€‚',
  'â€¦',
];

// éƒ¨åˆ†ä¸€è‡´ã§ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã™ã‚‹ãƒ•ãƒ¬ãƒ¼ã‚º
const HALLUCINATION_PARTIAL = [
  'ãƒãƒ£ãƒ³ãƒãƒ«ç™»éŒ²',
  'é«˜è©•ä¾¡ã¨ãƒãƒ£ãƒ³ãƒãƒ«ç™»éŒ²',
  'å­—å¹•',
  'subtitles',
  'ã”è¦–è´',
  'è¦–è´',
  'ã”è¦§ã„ãŸã ã',
  'ã”è¦§é ‚ã',
  'ãŠè´ã',
  'ãŠèã',
  'æ¬¡å›',
  'æ¬¡ã®å‹•ç”»',
  'ã¾ãŸä¼šã„ã¾ã—ã‚‡ã†',
  'ãŠæ¥½ã—ã¿ã«',
  'æä¾›',
  'ã‚¹ãƒãƒ³ã‚µãƒ¼',
  'åºƒå‘Š',
  'CM',
  'ã‚³ãƒãƒ¼ã‚·ãƒ£ãƒ«',
];

// å¹»è¦šãƒ•ãƒ¬ãƒ¼ã‚ºã‹ã©ã†ã‹ã‚’ãƒã‚§ãƒƒã‚¯
function isHallucination(text: string): boolean {
  const normalized = text.trim();
  const normalizedLower = normalized.toLowerCase();
  
  // å®Œå…¨ä¸€è‡´ãƒã‚§ãƒƒã‚¯
  for (const phrase of HALLUCINATION_EXACT) {
    if (normalized === phrase || normalizedLower === phrase.toLowerCase()) {
      console.log('[Whisper] Hallucination detected (exact):', normalized);
      return true;
    }
  }
  
  // éƒ¨åˆ†ä¸€è‡´ãƒã‚§ãƒƒã‚¯
  for (const phrase of HALLUCINATION_PARTIAL) {
    if (normalizedLower.includes(phrase.toLowerCase())) {
      console.log('[Whisper] Hallucination detected (partial):', normalized, 'matched:', phrase);
      return true;
    }
  }
  
  // çŸ­ã™ãã‚‹ãƒ†ã‚­ã‚¹ãƒˆã¯ãƒã‚¤ã‚ºã®å¯èƒ½æ€§ãŒé«˜ã„ï¼ˆ4æ–‡å­—ä»¥ä¸‹ï¼‰
  if (normalized.length <= 4) {
    console.log('[Whisper] Hallucination detected (too short):', normalized);
    return true;
  }
  
  // ã€Œï¼ã€ã§çµ‚ã‚ã‚‹çŸ­ã„ãƒ•ãƒ¬ãƒ¼ã‚ºã¯å¹»è¦šã®å¯èƒ½æ€§ãŒé«˜ã„
  if (normalized.endsWith('!') && normalized.length < 15) {
    console.log('[Whisper] Hallucination detected (short exclamation):', normalized);
    return true;
  }
  
  // åŒã˜æ–‡å­—ã®ç¹°ã‚Šè¿”ã—ï¼ˆä¾‹: "ã‚ã‚ã‚ã‚", "ã‚“ã‚“ã‚“ã‚“"ï¼‰
  if (/^(.)\1{3,}$/.test(normalized)) {
    console.log('[Whisper] Hallucination detected (repeated char):', normalized);
    return true;
  }
  
  // éŸ³æ¥½è¨˜å·ã‚„ç‰¹æ®Šæ–‡å­—ã®ã¿
  if (/^[â™ªâ™«â™¬â™­â™®â™¯â™©â—â—‹â– â–¡â–²â–³â˜…â˜†â€»â†’â†â†‘â†“ã€€ ]+$/.test(normalized)) {
    console.log('[Whisper] Hallucination detected (special chars only):', normalized);
    return true;
  }
  
  return false;
}

export function useWhisperRecognition(options: UseWhisperRecognitionOptions = {}) {
  const {
    silenceThreshold = 0.05, // 5%ä»¥ä¸‹ã¯ç„¡éŸ³ã¨åˆ¤å®š
    whisperPrompt = '', // Whisperã«æ¸¡ã™ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
  } = options;

  const [transcript, setTranscript] = useState<string>('');
  const [interimTranscript, setInterimTranscript] = useState<string>('');
  const [state, setState] = useState<RecognitionState>('idle');
  const [error, setError] = useState<string | null>(null);
  const [isSupported, setIsSupported] = useState<boolean>(false);
  const [isSpeechDetected, setIsSpeechDetected] = useState<boolean>(false);
  const [audioLevel, setAudioLevel] = useState<number>(0);
  const [isClipping, setIsClipping] = useState<boolean>(false);
  const [currentGain, setCurrentGain] = useState<number>(50); // åˆæœŸå€¤ã¯æœ€å¤§
  const [processingStatus, setProcessingStatus] = useState<string>('');

  const recorderRef = useRef<AudioRecorder | null>(null);
  const isProcessingRef = useRef<boolean>(false);
  const pendingTextRef = useRef<string>('');
  
  // Web Speech APIç”¨ï¼ˆãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ä»®ãƒ†ã‚­ã‚¹ãƒˆè¡¨ç¤ºç”¨ï¼‰
  // eslint-disable-next-line @typescript-eslint/no-explicit-any
  const webSpeechRef = useRef<any>(null);
  const webSpeechInterimRef = useRef<string>(''); // Web Speechã®ä»®ãƒ†ã‚­ã‚¹ãƒˆ
  const webSpeechFinalRef = useRef<string>(''); // Web Speechã®ç¢ºå®šãƒ†ã‚­ã‚¹ãƒˆï¼ˆè“„ç©ï¼‰
  
  // ã‚¢ãƒ‹ãƒ¡ãƒ¼ã‚·ãƒ§ãƒ³è¡¨ç¤ºç”¨
  const animationTimerRef = useRef<ReturnType<typeof setTimeout> | null>(null);
  const displayedTextRef = useRef<string>(''); // ç¾åœ¨è¡¨ç¤ºä¸­ã®ãƒ†ã‚­ã‚¹ãƒˆ
  const targetTextRef = useRef<string>(''); // ç›®æ¨™ãƒ†ã‚­ã‚¹ãƒˆ
  
  const whisperPromptRef = useRef<string>(whisperPrompt);
  const recentAudioLevelsRef = useRef<number[]>([]); // æœ€è¿‘ã®éŸ³å£°ãƒ¬ãƒ™ãƒ«ã‚’è¨˜éŒ²
  const maxAudioLevelRef = useRef<number>(0); // æœŸé–“ä¸­ã®æœ€å¤§éŸ³å£°ãƒ¬ãƒ™ãƒ«
  
  // VADï¼ˆç„¡éŸ³æ¤œå‡ºï¼‰ç”¨ - ç„¡éŸ³0.5ç§’ã§é€ä¿¡
  const speechStartTimeRef = useRef<number | null>(null); // ç™ºè©±é–‹å§‹æ™‚åˆ»
  const silenceStartTimeRef = useRef<number | null>(null); // ç„¡éŸ³é–‹å§‹æ™‚åˆ»
  const vadTimeoutRef = useRef<ReturnType<typeof setTimeout> | null>(null); // VADã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ
  const VAD_SILENCE_DURATION = 400; // ç„¡éŸ³ã¨åˆ¤å®šã™ã‚‹æ™‚é–“ï¼ˆ0.4ç§’ï¼‰
  const VAD_MIN_SPEECH_DURATION = 300; // æœ€ä½ç™ºè©±æ™‚é–“ï¼ˆ0.3ç§’ï¼‰
  const VAD_MAX_SPEECH_DURATION = 15000; // æœ€å¤§ç™ºè©±æ™‚é–“ï¼ˆ15ç§’ï¼‰- é•·ã™ãã‚‹ã®ã§çŸ­ç¸®
  const VAD_SPEECH_THRESHOLD = 0.015; // ç™ºè©±ã¨åˆ¤å®šã™ã‚‹é–¾å€¤ã‚’ã•ã‚‰ã«ä¸‹ã’ã¦æ•æ„Ÿã«ï¼ˆ1.5%ï¼‰

  // ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’refã§ä¿æŒï¼ˆå†ãƒ¬ãƒ³ãƒ€ãƒªãƒ³ã‚°ã‚’é˜²ãï¼‰
  useEffect(() => {
    whisperPromptRef.current = whisperPrompt;
    console.log('[Whisper] Prompt updated:', whisperPrompt?.slice(0, 50) + '...');
  }, [whisperPrompt]);

  // ã‚µãƒãƒ¼ãƒˆç¢ºèª
  useEffect(() => {
    const supported = typeof navigator.mediaDevices !== 'undefined' && 
      typeof navigator.mediaDevices.getUserMedia === 'function';
    setIsSupported(supported);
    if (!supported) {
      setError('ã“ã®ãƒ–ãƒ©ã‚¦ã‚¶ã¯éŸ³å£°éŒ²éŸ³ã‚’ã‚µãƒãƒ¼ãƒˆã—ã¦ã„ã¾ã›ã‚“ã€‚');
    }
  }, []);

  // Web Speech APIã®é–‹å§‹ï¼ˆãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ä»®ãƒ†ã‚­ã‚¹ãƒˆè¡¨ç¤ºç”¨ï¼‰
  const startWebSpeech = useCallback(() => {
    // Web Speech APIãŒåˆ©ç”¨å¯èƒ½ã‹ãƒã‚§ãƒƒã‚¯
    const SpeechRecognition = (window as any).SpeechRecognition || (window as any).webkitSpeechRecognition;
    if (!SpeechRecognition) {
      console.log('[WebSpeech] Not supported');
      return;
    }

    try {
      const recognition = new SpeechRecognition();
      recognition.lang = 'ja-JP';
      recognition.continuous = true;
      recognition.interimResults = true; // ä»®çµæœã‚’å–å¾—

      recognition.onresult = (event: any) => {
        let interim = '';
        let finalText = '';
        
        for (let i = event.resultIndex; i < event.results.length; i++) {
          const result = event.results[i];
          if (result.isFinal) {
            // ç¢ºå®šã—ãŸãƒ†ã‚­ã‚¹ãƒˆã‚’è“„ç©
            finalText += result[0].transcript;
          } else {
            // ä»®ãƒ†ã‚­ã‚¹ãƒˆ
            interim += result[0].transcript;
          }
        }
        
        // ç¢ºå®šãƒ†ã‚­ã‚¹ãƒˆãŒã‚ã‚Œã°è“„ç©
        if (finalText) {
          webSpeechFinalRef.current += finalText;
        }
        
        // ä»®ãƒ†ã‚­ã‚¹ãƒˆã‚’æ›´æ–°
        webSpeechInterimRef.current = interim;
        
        // è“„ç©ã—ãŸç¢ºå®šãƒ†ã‚­ã‚¹ãƒˆ + ç¾åœ¨ã®ä»®ãƒ†ã‚­ã‚¹ãƒˆã‚’ã‚¢ãƒ‹ãƒ¡ãƒ¼ã‚·ãƒ§ãƒ³è¡¨ç¤º
        const newTargetText = webSpeechFinalRef.current + interim;
        if (newTargetText && !isProcessingRef.current) {
          // ç›®æ¨™ãƒ†ã‚­ã‚¹ãƒˆãŒå¤‰ã‚ã£ãŸã‚‰ã‚¢ãƒ‹ãƒ¡ãƒ¼ã‚·ãƒ§ãƒ³é–‹å§‹
          if (newTargetText !== targetTextRef.current) {
            targetTextRef.current = newTargetText;
            startTypingAnimation();
          }
        }
      };
      
      // 1æ–‡å­—ãšã¤ã‚¢ãƒ‹ãƒ¡ãƒ¼ã‚·ãƒ§ãƒ³è¡¨ç¤º
      const startTypingAnimation = () => {
        // æ—¢å­˜ã®ã‚¢ãƒ‹ãƒ¡ãƒ¼ã‚·ãƒ§ãƒ³ã‚’ã‚­ãƒ£ãƒ³ã‚»ãƒ«
        if (animationTimerRef.current) {
          clearTimeout(animationTimerRef.current);
        }
        
        const animate = () => {
          const target = targetTextRef.current;
          const current = displayedTextRef.current;
          
          if (current.length < target.length) {
            // 1æ–‡å­—è¿½åŠ 
            displayedTextRef.current = target.slice(0, current.length + 1);
            setInterimTranscript(`ğŸ’¬ ${displayedTextRef.current}`);
            
            // æ¬¡ã®æ–‡å­—ã‚’è¡¨ç¤ºï¼ˆ40msé–“éš”ã§é«˜é€Ÿã«ï¼‰
            animationTimerRef.current = setTimeout(animate, 40);
          } else if (current.length > target.length) {
            // ã‚¿ãƒ¼ã‚²ãƒƒãƒˆãŒçŸ­ããªã£ãŸå ´åˆã¯å³åº§ã«æ›´æ–°
            displayedTextRef.current = target;
            setInterimTranscript(`ğŸ’¬ ${target}`);
          }
        };
        
        animate();
      };

      recognition.onerror = (event: any) => {
        console.log('[WebSpeech] Error:', event.error);
        // ã‚¨ãƒ©ãƒ¼æ™‚ã¯å†èµ·å‹•ã‚’è©¦ã¿ã‚‹
        if (event.error === 'no-speech' || event.error === 'aborted') {
          setTimeout(() => {
            if (webSpeechRef.current) {
              try {
                webSpeechRef.current.start();
              } catch (e) {
                // æ—¢ã«é–‹å§‹ã—ã¦ã„ã‚‹å ´åˆã¯ç„¡è¦–
              }
            }
          }, 100);
        }
      };

      recognition.onend = () => {
        console.log('[WebSpeech] Ended, restarting...');
        // éŒ²éŸ³ä¸­ãªã‚‰å†èµ·å‹•
        if (recorderRef.current?.isRecording()) {
          setTimeout(() => {
            if (webSpeechRef.current) {
              try {
                webSpeechRef.current.start();
              } catch (e) {
                // æ—¢ã«é–‹å§‹ã—ã¦ã„ã‚‹å ´åˆã¯ç„¡è¦–
              }
            }
          }, 100);
        }
      };

      recognition.start();
      webSpeechRef.current = recognition;
      console.log('[WebSpeech] Started');
    } catch (e) {
      console.error('[WebSpeech] Failed to start:', e);
    }
  }, []);

  // Web Speech APIã®åœæ­¢
  const stopWebSpeech = useCallback(() => {
    // ã‚¢ãƒ‹ãƒ¡ãƒ¼ã‚·ãƒ§ãƒ³ã‚¿ã‚¤ãƒãƒ¼ã‚’ã‚¯ãƒªã‚¢
    if (animationTimerRef.current) {
      clearTimeout(animationTimerRef.current);
      animationTimerRef.current = null;
    }
    displayedTextRef.current = '';
    targetTextRef.current = '';
    
    if (webSpeechRef.current) {
      try {
        webSpeechRef.current.stop();
      } catch (e) {
        // ç„¡è¦–
      }
      webSpeechRef.current = null;
      webSpeechInterimRef.current = '';
      webSpeechFinalRef.current = ''; // è“„ç©ãƒ†ã‚­ã‚¹ãƒˆã‚‚ã‚¯ãƒªã‚¢
      console.log('[WebSpeech] Stopped');
    }
  }, []);

  // ã‚²ã‚¤ãƒ³å€¤ã®å¤‰æ›´ï¼ˆéŒ²éŸ³ä¸­ã§ã‚‚ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã«åæ˜ ï¼‰
  const setGain = useCallback((value: number) => {
    setCurrentGain(value);
    if (recorderRef.current) {
      recorderRef.current.setGain(value);
    }
  }, []);

  // å®šæœŸçš„ã«éŸ³å£°ã‚’é€ä¿¡ã—ã¦æ–‡å­—èµ·ã“ã—
  const processAudio = useCallback(async () => {
    if (!recorderRef.current) {
      console.log('[Whisper] No recorder');
      return;
    }
    if (isProcessingRef.current) {
      console.log('[Whisper] Already processing');
      return;
    }
    if (!recorderRef.current.isRecording()) {
      console.log('[Whisper] Not recording');
      return;
    }

    // æœ€å¤§éŸ³å£°ãƒ¬ãƒ™ãƒ«ã‚’ãƒã‚§ãƒƒã‚¯ï¼ˆç„¡éŸ³ã®å ´åˆã¯ã‚¹ã‚­ãƒƒãƒ—ï¼‰
    const maxLevel = maxAudioLevelRef.current;
    console.log('[Whisper] Max audio level in period:', maxLevel);
    
    if (maxLevel < silenceThreshold) {
      console.log('[Whisper] Silence detected, skipping API call');
      setProcessingStatus(`ç„¡éŸ³æ¤œå‡ºï¼ˆãƒ¬ãƒ™ãƒ«: ${(maxLevel * 100).toFixed(0)}%ï¼‰`);
      // ãƒ‡ãƒ¼ã‚¿ã‚’ã‚¯ãƒªã‚¢ã—ã¦æ¬¡ã®æœŸé–“ã¸
      recorderRef.current.getIntermediateBlob();
      maxAudioLevelRef.current = 0;
      recentAudioLevelsRef.current = [];
      return;
    }

    const blob = recorderRef.current.getIntermediateBlob();
    console.log('[Whisper] Got blob:', blob?.size || 0, 'bytes');
    
    // æœ€å¤§ãƒ¬ãƒ™ãƒ«ã‚’ãƒªã‚»ãƒƒãƒˆ
    maxAudioLevelRef.current = 0;
    recentAudioLevelsRef.current = [];
    
    // æœ€å°ã‚µã‚¤ã‚ºãƒã‚§ãƒƒã‚¯ï¼ˆWAVãƒ˜ãƒƒãƒ€ãƒ¼44ãƒã‚¤ãƒˆ + æœ€ä½é™ã®ãƒ‡ãƒ¼ã‚¿ï¼‰
    if (!blob || blob.size < 1000) {
      setProcessingStatus('éŸ³å£°ãƒ‡ãƒ¼ã‚¿ä¸è¶³');
      return;
    }

    isProcessingRef.current = true;
    setProcessingStatus('Whisper APIã«é€ä¿¡ä¸­...');
    
    // Web Speechã®è“„ç©ãƒ†ã‚­ã‚¹ãƒˆã‚’ä¿æŒã—ã¦è¡¨ç¤ºï¼ˆè§£æä¸­ã‚‚èã„ãŸå†…å®¹ã‚’è¦‹ã›ã‚‹ï¼‰
    const currentWebSpeechText = webSpeechFinalRef.current + webSpeechInterimRef.current;
    if (currentWebSpeechText) {
      setInterimTranscript(`â˜ï¸ ${currentWebSpeechText}`);
    } else {
      setInterimTranscript('â˜ï¸ ã‚¯ãƒ©ã‚¦ãƒ‰ã§è§£æä¸­...');
    }

    try {
      console.log('[Whisper] Sending to API with prompt...');
      const result = await transcribeAudio(blob, whisperPromptRef.current);
      console.log('[Whisper] Result:', result);
      
      if (result.text && result.text.trim()) {
        const newText = result.text.trim();
        
        // å¹»è¦šãƒ•ãƒ¬ãƒ¼ã‚ºã‚’ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
        if (isHallucination(newText)) {
          console.log('[Whisper] Filtered hallucination:', newText);
          setProcessingStatus('ãƒã‚¤ã‚ºé™¤å»ï¼ˆå¹»è¦šãƒ•ã‚£ãƒ«ã‚¿ï¼‰');
          setInterimTranscript('ğŸ¤ æ¬¡ã®éŸ³å£°ã‚’å¾…æ©Ÿä¸­...');
        } else {
          // èªè­˜æˆåŠŸæ™‚ã¯å³åº§ã«ä¼šè©±æ¬„ã«ç§»å‹•
          console.log('[Whisper] Recognized text:', newText);
          
          // Web Speechã®è“„ç©ãƒ†ã‚­ã‚¹ãƒˆã‚’ã‚¯ãƒªã‚¢ï¼ˆWhisperçµæœãŒç¢ºå®šã—ãŸã®ã§ï¼‰
          webSpeechFinalRef.current = '';
          webSpeechInterimRef.current = '';
          // ã‚¢ãƒ‹ãƒ¡ãƒ¼ã‚·ãƒ§ãƒ³ç”¨ã®å¤‰æ•°ã‚‚ã‚¯ãƒªã‚¢
          displayedTextRef.current = '';
          targetTextRef.current = '';
          if (animationTimerRef.current) {
            clearTimeout(animationTimerRef.current);
            animationTimerRef.current = null;
          }
          
          // ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æ¬„ã«çµæœã‚’å³åº§ã«è¡¨ç¤ºï¼ˆãƒã‚§ãƒƒã‚¯ãƒãƒ¼ã‚¯ä»˜ãã§Whisperçµæœã‚’è¡¨ç¤ºï¼‰
          setInterimTranscript(`âœ… ${newText}`);
          
          // ä¼šè©±æ¬„ã«è¿½åŠ ï¼ˆç”Ÿã®OpenAIå‡ºåŠ›ã€æ•´å½¢ã¯App.tsxå´ã§è¡Œã†ï¼‰
          setTranscript((prev) => {
            const newTranscript = prev ? prev + '\n' + newText : newText;
            console.log('[Whisper] New transcript:', newTranscript);
            return newTranscript;
          });
          
          setProcessingStatus('èªè­˜æˆåŠŸ: ' + newText.substring(0, 20) + '...');
          
          // 3ç§’å¾Œã«ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æ¬„ã‚’ã‚¯ãƒªã‚¢ï¼ˆæ¬¡ã®éŸ³å£°å¾…æ©Ÿã«æˆ»ã‚‹ï¼‰
          // ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒèª­ã¿åˆ‡ã‚Œã‚‹ã‚ˆã†ã«å°‘ã—é•·ã‚ã«ä¿æŒ
          setTimeout(() => {
            setInterimTranscript((current) => {
              // ã‚‚ã—æ—¢ã«æ¬¡ã®éŸ³å£°ãŒå…¥ã£ã¦ãã¦ã„ãŸã‚‰ä¸Šæ›¸ãã—ãªã„
              if (current === newText) {
                return 'ğŸ¤ æ¬¡ã®éŸ³å£°ã‚’å¾…æ©Ÿä¸­...';
              }
              return current;
            });
          }, 3000);
        }
      } else {
        setProcessingStatus('éŸ³å£°ãªã—ï¼ˆç„¡éŸ³ï¼‰');
        setInterimTranscript('ğŸ¤ æ¬¡ã®éŸ³å£°ã‚’å¾…æ©Ÿä¸­...');
      }
    } catch (e) {
      console.error('[Whisper] Transcription error:', e);
      setProcessingStatus('ã‚¨ãƒ©ãƒ¼: ' + (e instanceof Error ? e.message : 'ä¸æ˜'));
      if (e instanceof Error && e.message.includes('401')) {
        setError('OpenAI APIã‚­ãƒ¼ãŒç„¡åŠ¹ã§ã™ã€‚è¨­å®šã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚');
      } else if (e instanceof Error && e.message.includes('429')) {
        setError('APIåˆ¶é™ã«é”ã—ã¾ã—ãŸã€‚ã—ã°ã‚‰ãå¾…ã£ã¦ãã ã•ã„ã€‚');
      }
    } finally {
      isProcessingRef.current = false;
    }
  }, [silenceThreshold]);

  // èªè­˜æˆåŠŸæ™‚ã«å³åº§ã«ä¼šè©±æ¬„ã«ç§»å‹•ã™ã‚‹ã®ã§ã€å®šæœŸçš„ãªflushã¯ä¸è¦

  const startListening = useCallback(async () => {
    if (!isSupported) {
      setError('éŸ³å£°éŒ²éŸ³ã¯ã‚µãƒãƒ¼ãƒˆã•ã‚Œã¦ã„ã¾ã›ã‚“');
      return;
    }

    setError(null);
    setState('starting');
    pendingTextRef.current = '';
    maxAudioLevelRef.current = 0;
    recentAudioLevelsRef.current = [];
    setProcessingStatus('é–‹å§‹ä¸­...');

    try {
      const recorder = new AudioRecorder();
      recorder.setGain(currentGain);
      
      await recorder.start((level, clipping) => {
        setAudioLevel(level);
        setIsClipping(clipping);
        // æœ€å¤§ãƒ¬ãƒ™ãƒ«ã‚’æ›´æ–°
        if (level > maxAudioLevelRef.current) {
          maxAudioLevelRef.current = level;
        }
        recentAudioLevelsRef.current.push(level);
        // æœ€æ–°100ä»¶ã®ã¿ä¿æŒ
        if (recentAudioLevelsRef.current.length > 100) {
          recentAudioLevelsRef.current.shift();
        }
        // ã‚ˆã‚Šä½ã„é–¾å€¤ã§éŸ³å£°æ¤œå‡º
        const isSpeaking = level > VAD_SPEECH_THRESHOLD;
        setIsSpeechDetected(isSpeaking);
        
        // VADãƒ­ã‚¸ãƒƒã‚¯
        const now = Date.now();
        
        if (isSpeaking) {
          // ç™ºè©±ä¸­ - ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ è¡¨ç¤ºã‚’æ›´æ–°
          if (speechStartTimeRef.current === null) {
            speechStartTimeRef.current = now;
            console.log('[VAD] Speech started');
          }
          // ç™ºè©±ä¸­ã®ç§’æ•°ã‚’è¡¨ç¤º
          // Web Speechã®ä»®ãƒ†ã‚­ã‚¹ãƒˆãŒã‚ã‚Œã°ãã‚Œã‚’è¡¨ç¤ºã€ãªã‘ã‚Œã°ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹è¡¨ç¤º
          if (webSpeechInterimRef.current && !isProcessingRef.current) {
            setInterimTranscript(`ğŸ’¬ ${webSpeechInterimRef.current}`);
          } else if (!isProcessingRef.current) {
            const speechDuration = Math.floor((now - speechStartTimeRef.current) / 1000);
            setInterimTranscript(`ğŸ”Š è´ã„ã¦ã„ã¾ã™... (${speechDuration}ç§’)`);
          }
          silenceStartTimeRef.current = null;
          
          // VADã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã‚’ã‚¯ãƒªã‚¢
          if (vadTimeoutRef.current) {
            clearTimeout(vadTimeoutRef.current);
            vadTimeoutRef.current = null;
          }
          
          // æœ€å¤§ç™ºè©±æ™‚é–“ã‚’è¶…ãˆãŸã‚‰å¼·åˆ¶é€ä¿¡
          if (speechStartTimeRef.current && (now - speechStartTimeRef.current) > VAD_MAX_SPEECH_DURATION) {
            console.log('[VAD] Max speech duration reached, forcing send');
            processAudio();
            speechStartTimeRef.current = now; // ãƒªã‚»ãƒƒãƒˆã—ã¦ç¶™ç¶š
          }
        } else {
          // ç„¡éŸ³
          if (speechStartTimeRef.current === null && !isProcessingRef.current) {
            // ã¾ã ç™ºè©±ãŒå§‹ã¾ã£ã¦ã„ãªã„
            setInterimTranscript('ğŸ¤ éŸ³å£°ã‚’å¾…æ©Ÿä¸­...');
          }
          if (speechStartTimeRef.current !== null) {
            // ç™ºè©±å¾Œã®ç„¡éŸ³
            if (silenceStartTimeRef.current === null) {
              silenceStartTimeRef.current = now;
            }
            
            const silenceDuration = now - silenceStartTimeRef.current;
            const speechDuration = now - speechStartTimeRef.current;
            
            // ç„¡éŸ³ä¸­ã®è¡¨ç¤º
            if (silenceDuration > 100) {
              setInterimTranscript(`â³ è¨€è‘‰ã®åŒºåˆ‡ã‚Šã‚’å¾…æ©Ÿä¸­... (${(silenceDuration/1000).toFixed(1)}ç§’)`);
            }
            
            // ç„¡éŸ³ãŒä¸€å®šæ™‚é–“ç¶šã„ãŸã‚‰é€ä¿¡
            if (silenceDuration >= VAD_SILENCE_DURATION && speechDuration >= VAD_MIN_SPEECH_DURATION) {
              // æ—¢ã«å‡¦ç†ä¸­ã®å ´åˆã¯é€ä¿¡ã ã‘ã‚¹ã‚­ãƒƒãƒ—ï¼ˆreturnã—ãªã„ï¼‰
              if (!isProcessingRef.current && !vadTimeoutRef.current) {
                vadTimeoutRef.current = setTimeout(() => {
                  console.log('[VAD] Silence detected after speech, sending audio');
                  processAudio();
                  speechStartTimeRef.current = null;
                  silenceStartTimeRef.current = null;
                  vadTimeoutRef.current = null;
                }, 50); // å°‘ã—å¾…ã£ã¦ã‹ã‚‰é€ä¿¡
              }
            }
          }
        }
      });

      recorderRef.current = recorder;
      setState('listening');
      setProcessingStatus('è§£æä¸­');

      // Web Speech APIã‚’ä¸¦è¡Œã§é–‹å§‹ï¼ˆãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ä»®ãƒ†ã‚­ã‚¹ãƒˆç”¨ï¼‰
      startWebSpeech();

      // VADã®ã¿ã§å‹•ä½œï¼ˆå›ºå®šé–“éš”ãªã—ï¼‰
      // èªè­˜æˆåŠŸæ™‚ã«å³åº§ã«ä¼šè©±æ¬„ã«ç§»å‹•ã™ã‚‹ã®ã§flushä¸è¦

    } catch (e) {
      console.error('[Whisper] Failed to start:', e);
      setError('ãƒã‚¤ã‚¯ã®ä½¿ç”¨ãŒè¨±å¯ã•ã‚Œã¦ã„ã¾ã›ã‚“');
      setState('idle');
      setProcessingStatus('');
    }
  }, [isSupported, currentGain, processAudio, startWebSpeech]);

  const stopListening = useCallback(async () => {
    setState('stopping');
    setProcessingStatus('åœæ­¢ä¸­...');

    // Web Speech APIã‚’åœæ­¢
    stopWebSpeech();

    // VADã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã‚’ã‚¯ãƒªã‚¢
    if (vadTimeoutRef.current) {
      clearTimeout(vadTimeoutRef.current);
      vadTimeoutRef.current = null;
    }
    speechStartTimeRef.current = null;
    silenceStartTimeRef.current = null;

    // æœ€å¾Œã®éŸ³å£°ã‚’å‡¦ç†
    if (recorderRef.current) {
      const finalBlob = recorderRef.current.stop();
      
      // ç„¡éŸ³ã§ãªãã€ååˆ†ãªã‚µã‚¤ã‚ºãŒã‚ã‚‹å ´åˆã®ã¿å‡¦ç†
      if (finalBlob && finalBlob.size > 1000 && maxAudioLevelRef.current >= silenceThreshold) {
        setState('processing');
        setInterimTranscript('æœ€çµ‚å‡¦ç†ä¸­...');
        setProcessingStatus('æœ€çµ‚å‡¦ç†ä¸­...');
        
        try {
          const result = await transcribeAudio(finalBlob, whisperPromptRef.current);
          if (result.text && result.text.trim() && !isHallucination(result.text.trim())) {
            pendingTextRef.current = pendingTextRef.current 
              ? pendingTextRef.current + ' ' + result.text.trim() 
              : result.text.trim();
          }
        } catch (e) {
          console.error('[Whisper] Final transcription error:', e);
        }
      }
      
      recorderRef.current = null;
    }

    // èªè­˜æˆåŠŸæ™‚ã«å³åº§ã«ä¼šè©±æ¬„ã«ç§»å‹•ã™ã‚‹ã®ã§ã€flushä¸è¦

    setState('idle');
    setInterimTranscript('');
    setIsSpeechDetected(false);
    setAudioLevel(0);
    setProcessingStatus('');
    maxAudioLevelRef.current = 0;
    recentAudioLevelsRef.current = [];
  }, [silenceThreshold, stopWebSpeech]);

  const clearTranscript = useCallback(() => {
    setTranscript('');
    setInterimTranscript('');
    pendingTextRef.current = '';
  }, []);

  // ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
  useEffect(() => {
    return () => {
      if (vadTimeoutRef.current) {
        clearTimeout(vadTimeoutRef.current);
      }
      if (recorderRef.current) {
        recorderRef.current.stop();
      }
    };
  }, []);

  return {
    transcript,
    interimTranscript,
    state,
    isListening: state === 'listening' || state === 'processing',
    isSpeechDetected,
    isClipping,
    error,
    isSupported,
    audioLevel,
    currentGain,
    processingStatus,
    setGain,
    startListening,
    stopListening,
    clearTranscript,
  };
}

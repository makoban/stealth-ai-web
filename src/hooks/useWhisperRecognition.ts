import { useState, useEffect, useRef, useCallback } from 'react';
import { AudioRecorder, transcribeAudio } from '../lib/whisper';

export type RecognitionState = 'idle' | 'starting' | 'listening' | 'processing' | 'stopping';

export interface UseWhisperRecognitionOptions {
  intervalMs?: number;
  silenceThreshold?: number;
  whisperPrompt?: string;
  onBufferReady?: (text: string) => void; // Geminié€ä¿¡ç”¨ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯
}

// å¹»è¦šãƒ•ãƒ¬ãƒ¼ã‚ºï¼ˆå®Œå…¨ä¸€è‡´ï¼‰
const HALLUCINATION_EXACT = [
  'ã”è¦–è´ã‚ã‚ŠãŒã¨ã†ã”ã–ã„ã¾ã—ãŸ', 'ã”è¦–è´ã‚ã‚ŠãŒã¨ã†ã”ã–ã„ã¾ã™',
  'ã‚ã‚ŠãŒã¨ã†ã”ã–ã„ã¾ã—ãŸ', 'ã‚ã‚ŠãŒã¨ã†ã”ã–ã„ã¾ã™',
  'ãŠç–²ã‚Œæ§˜ã§ã—ãŸ', 'ãŠã‚„ã™ã¿ãªã•ã„', 'ã•ã‚ˆã†ãªã‚‰',
  'Thank you for watching', 'Subscribe',
  '...', 'ã€‚ã€‚ã€‚', 'â€¦',
];

// å¹»è¦šãƒ•ãƒ¬ãƒ¼ã‚ºï¼ˆéƒ¨åˆ†ä¸€è‡´ï¼‰
const HALLUCINATION_PARTIAL = [
  'ãƒãƒ£ãƒ³ãƒãƒ«ç™»éŒ²', 'ã”è¦–è´', 'è¦–è´', 'æ¬¡å›', 'æ¬¡ã®å‹•ç”»',
];

function isHallucination(text: string): boolean {
  const normalized = text.trim();
  const lower = normalized.toLowerCase();
  
  for (const phrase of HALLUCINATION_EXACT) {
    if (normalized === phrase || lower === phrase.toLowerCase()) return true;
  }
  for (const phrase of HALLUCINATION_PARTIAL) {
    if (lower.includes(phrase.toLowerCase())) return true;
  }
  if (normalized.length <= 4) return true;
  if (/^(.)\1{3,}$/.test(normalized)) return true;
  
  return false;
}

export function useWhisperRecognition(options: UseWhisperRecognitionOptions = {}) {
  const {
    silenceThreshold = 0.05,
    whisperPrompt = '',
    onBufferReady,
  } = options;

  const [transcript, setTranscript] = useState<string>('');
  const [interimTranscript, setInterimTranscript] = useState<string>('');
  const [state, setState] = useState<RecognitionState>('idle');
  const [error, setError] = useState<string | null>(null);
  const [isSupported, setIsSupported] = useState<boolean>(false);
  const [isSpeechDetected, setIsSpeechDetected] = useState<boolean>(false);
  const [audioLevel, setAudioLevel] = useState<number>(0);
  const [isClipping, setIsClipping] = useState<boolean>(false);
  const [currentGain, setCurrentGain] = useState<number>(50);
  const [processingStatus, setProcessingStatus] = useState<string>('');

  const recorderRef = useRef<AudioRecorder | null>(null);
  const isProcessingRef = useRef<boolean>(false);
  
  // ã‚¿ã‚¤ãƒ—ãƒ©ã‚¤ã‚¿ãƒ¼ç”¨
  const typingTimerRef = useRef<ReturnType<typeof setInterval> | null>(null);
  const typingIndexRef = useRef<number>(0);
  const typingTextRef = useRef<string>('');
  const displayedTextRef = useRef<string>(''); // ç¾åœ¨è¡¨ç¤ºä¸­ã®ãƒ†ã‚­ã‚¹ãƒˆ
  
  // Whisperå®šæœŸé€ä¿¡ç”¨ï¼ˆ1.5ç§’ã”ã¨ï¼‰
  const whisperIntervalRef = useRef<ReturnType<typeof setInterval> | null>(null);
  const WHISPER_INTERVAL = 1500; // 1.5ç§’ã”ã¨ã«Whisperé€ä¿¡
  
  // Geminié€ä¿¡ç”¨ãƒãƒƒãƒ•ã‚¡
  const geminiBufferRef = useRef<string>('');
  const geminiTimerRef = useRef<ReturnType<typeof setTimeout> | null>(null);
  const GEMINI_FLUSH_DELAY = 400; // 0.4ç§’ç„¡éŸ³ã§Geminié€ä¿¡
  
  // VADç”¨ï¼ˆGeminié€ä¿¡ãƒˆãƒªã‚¬ãƒ¼ï¼‰
  const lastSpeechTimeRef = useRef<number>(Date.now());
  const VAD_SPEECH_THRESHOLD = 0.015;
  
  const whisperPromptRef = useRef<string>(whisperPrompt);
  const onBufferReadyRef = useRef(onBufferReady);
  const maxAudioLevelRef = useRef<number>(0);

  useEffect(() => {
    onBufferReadyRef.current = onBufferReady;
  }, [onBufferReady]);

  useEffect(() => {
    whisperPromptRef.current = whisperPrompt;
  }, [whisperPrompt]);

  useEffect(() => {
    const supported = typeof navigator.mediaDevices !== 'undefined' && 
      typeof navigator.mediaDevices.getUserMedia === 'function';
    setIsSupported(supported);
    if (!supported) {
      setError('ã“ã®ãƒ–ãƒ©ã‚¦ã‚¶ã¯éŸ³å£°éŒ²éŸ³ã‚’ã‚µãƒãƒ¼ãƒˆã—ã¦ã„ã¾ã›ã‚“ã€‚');
    }
  }, []);

  // 20æ–‡å­—ã‚¹ã‚¯ãƒ­ãƒ¼ãƒ«è¡¨ç¤ºç”¨ã®ãƒ˜ãƒ«ãƒ‘ãƒ¼
  const MAX_DISPLAY_CHARS = 20;
  
  const getScrolledText = useCallback((text: string) => {
    if (text.length <= MAX_DISPLAY_CHARS) {
      return text;
    }
    // 20æ–‡å­—ã‚’è¶…ãˆãŸã‚‰æœ€æ–°ã®20æ–‡å­—ã‚’è¡¨ç¤ºï¼ˆå·¦ã‚¹ã‚¯ãƒ­ãƒ¼ãƒ«ï¼‰
    return '...' + text.slice(-MAX_DISPLAY_CHARS);
  }, []);

  // ã‚¿ã‚¤ãƒ—ãƒ©ã‚¤ã‚¿ãƒ¼ã‚¢ãƒ‹ãƒ¡ãƒ¼ã‚·ãƒ§ãƒ³ï¼ˆæ–°ã—ã„ãƒ†ã‚­ã‚¹ãƒˆã‚’è¿½åŠ ã€20æ–‡å­—ã‚¹ã‚¯ãƒ­ãƒ¼ãƒ«ï¼‰
  const appendTyping = useCallback((newText: string) => {
    // æ—¢å­˜ã®ã‚¿ã‚¤ãƒãƒ¼ã‚’ã‚¯ãƒªã‚¢
    if (typingTimerRef.current) {
      clearInterval(typingTimerRef.current);
    }
    
    // æ–°ã—ã„ãƒ†ã‚­ã‚¹ãƒˆã‚’è¿½åŠ 
    const fullText = displayedTextRef.current ? displayedTextRef.current + ' ' + newText : newText;
    typingTextRef.current = fullText;
    typingIndexRef.current = displayedTextRef.current.length; // æ—¢å­˜éƒ¨åˆ†ã¯ã‚¹ã‚­ãƒƒãƒ—
    
    // 50msã”ã¨ã«1æ–‡å­—è¿½åŠ 
    typingTimerRef.current = setInterval(() => {
      typingIndexRef.current++;
      const displayed = typingTextRef.current.slice(0, typingIndexRef.current);
      displayedTextRef.current = displayed;
      // 20æ–‡å­—ã‚¹ã‚¯ãƒ­ãƒ¼ãƒ«è¡¨ç¤º
      setInterimTranscript(`ğŸ’¬ ${getScrolledText(displayed)}`);
      
      // å…¨æ–‡å­—è¡¨ç¤ºã—ãŸã‚‰ã‚¿ã‚¤ãƒãƒ¼åœæ­¢
      if (typingIndexRef.current >= typingTextRef.current.length) {
        if (typingTimerRef.current) {
          clearInterval(typingTimerRef.current);
          typingTimerRef.current = null;
        }
      }
    }, 50);
  }, [getScrolledText]);

  // Geminiãƒãƒƒãƒ•ã‚¡ã‚’ãƒ•ãƒ©ãƒƒã‚·ãƒ¥ã—ã¦Geminié€ä¿¡
  const flushGeminiBuffer = useCallback(() => {
    const buffer = geminiBufferRef.current.trim();
    if (buffer && onBufferReadyRef.current) {
      console.log('[Whisper] Flushing to Gemini:', buffer);
      onBufferReadyRef.current(buffer);
      
      // ãƒãƒƒãƒ•ã‚¡ã¨ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ è¡¨ç¤ºã‚’ã‚¯ãƒªã‚¢
      geminiBufferRef.current = '';
      displayedTextRef.current = '';
      typingTextRef.current = '';
      typingIndexRef.current = 0;
      setInterimTranscript('ğŸ¤ æ¬¡ã®éŸ³å£°ã‚’å¾…æ©Ÿä¸­...');
    }
  }, []);

  // Geminiã‚¿ã‚¤ãƒãƒ¼ãƒªã‚»ãƒƒãƒˆï¼ˆ0.4ç§’ç„¡éŸ³ã§Geminié€ä¿¡ï¼‰
  const resetGeminiTimer = useCallback(() => {
    if (geminiTimerRef.current) {
      clearTimeout(geminiTimerRef.current);
    }
    if (geminiBufferRef.current.trim()) {
      geminiTimerRef.current = setTimeout(flushGeminiBuffer, GEMINI_FLUSH_DELAY);
    }
  }, [flushGeminiBuffer]);

  const setGain = useCallback((value: number) => {
    setCurrentGain(value);
    if (recorderRef.current) {
      recorderRef.current.setGain(value);
    }
  }, []);

  // Whisperé€ä¿¡ï¼ˆå®šæœŸçš„ã«å‘¼ã°ã‚Œã‚‹ï¼‰
  const sendToWhisper = useCallback(async () => {
    if (!recorderRef.current || isProcessingRef.current || !recorderRef.current.isRecording()) {
      return;
    }

    const maxLevel = maxAudioLevelRef.current;
    
    // ç„¡éŸ³ã®å ´åˆã¯ã‚¹ã‚­ãƒƒãƒ—
    if (maxLevel < silenceThreshold) {
      recorderRef.current.getIntermediateBlob();
      maxAudioLevelRef.current = 0;
      return;
    }

    const blob = recorderRef.current.getIntermediateBlob();
    maxAudioLevelRef.current = 0;
    
    if (!blob || blob.size < 1000) return;

    isProcessingRef.current = true;
    setProcessingStatus('Whisperé€ä¿¡ä¸­...');

    try {
      const result = await transcribeAudio(blob, whisperPromptRef.current);
      
      if (result.text && result.text.trim()) {
        const newText = result.text.trim();
        
        if (isHallucination(newText)) {
          setProcessingStatus('ãƒã‚¤ã‚ºé™¤å»');
        } else {
          console.log('[Whisper] Recognized:', newText);
          
          // Geminiãƒãƒƒãƒ•ã‚¡ã«è¿½åŠ 
          if (geminiBufferRef.current) {
            geminiBufferRef.current += ' ' + newText;
          } else {
            geminiBufferRef.current = newText;
          }
          
          // ã‚¿ã‚¤ãƒ—ãƒ©ã‚¤ã‚¿ãƒ¼è¡¨ç¤ºï¼ˆè¿½åŠ ï¼‰
          appendTyping(newText);
          
          // transcriptæ›´æ–°ï¼ˆä¼šè©±æ¬„ç”¨ - Geminiæ•´å½¢å¾Œã«ä½¿ç”¨ï¼‰
          setTranscript(prev => prev ? prev + '\n' + newText : newText);
          setProcessingStatus('èªè­˜æˆåŠŸ');
          
          // ç™ºè©±ãŒã‚ã£ãŸã®ã§Geminiã‚¿ã‚¤ãƒãƒ¼ãƒªã‚»ãƒƒãƒˆ
          lastSpeechTimeRef.current = Date.now();
          resetGeminiTimer();
        }
      } else {
        setProcessingStatus('éŸ³å£°ãªã—');
      }
    } catch (e) {
      console.error('[Whisper] Error:', e);
      setProcessingStatus('ã‚¨ãƒ©ãƒ¼');
    } finally {
      isProcessingRef.current = false;
    }
  }, [silenceThreshold, appendTyping, resetGeminiTimer]);

  const startListening = useCallback(async () => {
    if (!isSupported) {
      setError('éŸ³å£°éŒ²éŸ³ã¯ã‚µãƒãƒ¼ãƒˆã•ã‚Œã¦ã„ã¾ã›ã‚“');
      return;
    }

    setError(null);
    setState('starting');
    geminiBufferRef.current = '';
    displayedTextRef.current = '';
    typingTextRef.current = '';
    typingIndexRef.current = 0;
    maxAudioLevelRef.current = 0;
    lastSpeechTimeRef.current = Date.now();

    try {
      const recorder = new AudioRecorder();
      recorder.setGain(currentGain);
      
      await recorder.start((level, clipping) => {
        setAudioLevel(level);
        setIsClipping(clipping);
        if (level > maxAudioLevelRef.current) {
          maxAudioLevelRef.current = level;
        }
        
        const isSpeaking = level > VAD_SPEECH_THRESHOLD;
        setIsSpeechDetected(isSpeaking);
        
        if (isSpeaking) {
          lastSpeechTimeRef.current = Date.now();
          // ç™ºè©±ä¸­ã¯Geminiã‚¿ã‚¤ãƒãƒ¼ã‚’ã‚¯ãƒªã‚¢
          if (geminiTimerRef.current) {
            clearTimeout(geminiTimerRef.current);
            geminiTimerRef.current = null;
          }
        } else {
          // ç„¡éŸ³ãŒç¶šã„ãŸã‚‰Geminiã‚¿ã‚¤ãƒãƒ¼é–‹å§‹
          const silenceDuration = Date.now() - lastSpeechTimeRef.current;
          if (silenceDuration >= GEMINI_FLUSH_DELAY && geminiBufferRef.current.trim() && !geminiTimerRef.current) {
            resetGeminiTimer();
          }
        }
        
        // ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ è¡¨ç¤ºæ›´æ–°ï¼ˆã‚¿ã‚¤ãƒ—ãƒ©ã‚¤ã‚¿ãƒ¼ä¸­ã§ãªã‘ã‚Œã°ï¼‰
        if (!typingTimerRef.current && !isProcessingRef.current) {
          if (isSpeaking) {
            if (displayedTextRef.current) {
              // 20æ–‡å­—ã‚¹ã‚¯ãƒ­ãƒ¼ãƒ«è¡¨ç¤º
              const scrolled = displayedTextRef.current.length > 20 
                ? '...' + displayedTextRef.current.slice(-20) 
                : displayedTextRef.current;
              setInterimTranscript(`ğŸ”Š ${scrolled}...`);
            } else {
              setInterimTranscript('ğŸ”Š è´ã„ã¦ã„ã¾ã™...');
            }
          } else if (!displayedTextRef.current) {
            setInterimTranscript('ğŸ¤ éŸ³å£°ã‚’å¾…æ©Ÿä¸­...');
          }
        }
      });

      recorderRef.current = recorder;
      setState('listening');
      setProcessingStatus('è§£æä¸­');
      
      // Whisperå®šæœŸé€ä¿¡é–‹å§‹ï¼ˆ1.5ç§’ã”ã¨ï¼‰
      whisperIntervalRef.current = setInterval(() => {
        sendToWhisper();
      }, WHISPER_INTERVAL);

    } catch (e) {
      console.error('[Whisper] Failed to start:', e);
      setError('ãƒã‚¤ã‚¯ã®ä½¿ç”¨ãŒè¨±å¯ã•ã‚Œã¦ã„ã¾ã›ã‚“');
      setState('idle');
    }
  }, [isSupported, currentGain, sendToWhisper, resetGeminiTimer]);

  const stopListening = useCallback(async () => {
    setState('stopping');

    // ã‚¿ã‚¤ãƒãƒ¼ã‚¯ãƒªã‚¢
    if (typingTimerRef.current) {
      clearInterval(typingTimerRef.current);
      typingTimerRef.current = null;
    }
    if (whisperIntervalRef.current) {
      clearInterval(whisperIntervalRef.current);
      whisperIntervalRef.current = null;
    }
    if (geminiTimerRef.current) {
      clearTimeout(geminiTimerRef.current);
      geminiTimerRef.current = null;
    }
    
    // æ®‹ã‚Šãƒãƒƒãƒ•ã‚¡ã‚’Geminiã«é€ä¿¡
    if (geminiBufferRef.current.trim() && onBufferReadyRef.current) {
      onBufferReadyRef.current(geminiBufferRef.current.trim());
    }
    
    geminiBufferRef.current = '';
    displayedTextRef.current = '';

    if (recorderRef.current) {
      const finalBlob = recorderRef.current.stop();
      
      if (finalBlob && finalBlob.size > 1000 && maxAudioLevelRef.current >= silenceThreshold) {
        setState('processing');
        setInterimTranscript('æœ€çµ‚å‡¦ç†ä¸­...');
        
        try {
          const result = await transcribeAudio(finalBlob, whisperPromptRef.current);
          if (result.text && result.text.trim() && !isHallucination(result.text.trim())) {
            const finalText = result.text.trim();
            setTranscript(prev => prev ? prev + '\n' + finalText : finalText);
            if (onBufferReadyRef.current) {
              onBufferReadyRef.current(finalText);
            }
          }
        } catch (e) {
          console.error('[Whisper] Final error:', e);
        }
      }
      
      recorderRef.current = null;
    }

    setState('idle');
    setInterimTranscript('');
    setIsSpeechDetected(false);
    setAudioLevel(0);
    setProcessingStatus('');
    maxAudioLevelRef.current = 0;
  }, [silenceThreshold]);

  const clearTranscript = useCallback(() => {
    setTranscript('');
    setInterimTranscript('');
    geminiBufferRef.current = '';
    displayedTextRef.current = '';
    typingTextRef.current = '';
    typingIndexRef.current = 0;
  }, []);

  useEffect(() => {
    return () => {
      if (whisperIntervalRef.current) clearInterval(whisperIntervalRef.current);
      if (typingTimerRef.current) clearInterval(typingTimerRef.current);
      if (geminiTimerRef.current) clearTimeout(geminiTimerRef.current);
      if (recorderRef.current) recorderRef.current.stop();
    };
  }, []);

  return {
    transcript,
    interimTranscript,
    state,
    isListening: state === 'listening' || state === 'processing',
    isSpeechDetected,
    isClipping,
    error,
    isSupported,
    audioLevel,
    currentGain,
    processingStatus,
    setGain,
    startListening,
    stopListening,
    clearTranscript,
  };
}
